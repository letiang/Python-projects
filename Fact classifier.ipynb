{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxHgK+5FDzFkLi3YY5dKYK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":35,"metadata":{"id":"N7y3KQlSqx9g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727415784141,"user_tz":240,"elapsed":15550,"user":{"displayName":"Letian Gao","userId":"10046384146796585092"}},"outputId":"4fa88287-98a1-4b0c-e4d2-86596fe2364c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning parameters for LogisticRegression with None preprocessing...\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters for LogisticRegression: {'classifier__C': 1, 'classifier__max_iter': 100}, Best F1 Score: 0.91\n","Vectorizer: TfidfVectorizer(), Classifier: LogisticRegression, Preprocess: None, Accuracy: 0.95, F1 Score: 0.95\n","Tuning parameters for SVC with None preprocessing...\n","Best parameters for SVC: {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: SVC, Preprocess: None, Accuracy: 0.93, F1 Score: 0.91\n","Tuning parameters for MultinomialNB with None preprocessing...\n","Best parameters for MultinomialNB: {'classifier__alpha': 1.0}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: MultinomialNB, Preprocess: None, Accuracy: 0.95, F1 Score: 0.95\n","Tuning parameters for LogisticRegression with Lemmatizer preprocessing...\n","Best parameters for LogisticRegression: {'classifier__C': 10, 'classifier__max_iter': 100}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: LogisticRegression, Preprocess: Lemmatizer, Accuracy: 0.95, F1 Score: 0.94\n","Tuning parameters for SVC with Lemmatizer preprocessing...\n","Best parameters for SVC: {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, Best F1 Score: 0.91\n","Vectorizer: TfidfVectorizer(), Classifier: SVC, Preprocess: Lemmatizer, Accuracy: 0.90, F1 Score: 0.88\n","Tuning parameters for MultinomialNB with Lemmatizer preprocessing...\n","Best parameters for MultinomialNB: {'classifier__alpha': 1.0}, Best F1 Score: 0.93\n","Vectorizer: TfidfVectorizer(), Classifier: MultinomialNB, Preprocess: Lemmatizer, Accuracy: 0.97, F1 Score: 0.97\n","Tuning parameters for LogisticRegression with Stemmer preprocessing...\n","Best parameters for LogisticRegression: {'classifier__C': 10, 'classifier__max_iter': 100}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: LogisticRegression, Preprocess: Stemmer, Accuracy: 0.97, F1 Score: 0.97\n","Tuning parameters for SVC with Stemmer preprocessing...\n","Best parameters for SVC: {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: SVC, Preprocess: Stemmer, Accuracy: 0.97, F1 Score: 0.97\n","Tuning parameters for MultinomialNB with Stemmer preprocessing...\n","Best parameters for MultinomialNB: {'classifier__alpha': 1.0}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: MultinomialNB, Preprocess: Stemmer, Accuracy: 0.97, F1 Score: 0.97\n","Tuning parameters for LogisticRegression with Stop_words preprocessing...\n","Best parameters for LogisticRegression: {'classifier__C': 10, 'classifier__max_iter': 100}, Best F1 Score: 0.87\n","Vectorizer: TfidfVectorizer(), Classifier: LogisticRegression, Preprocess: Stop_words, Accuracy: 0.93, F1 Score: 0.91\n","Tuning parameters for SVC with Stop_words preprocessing...\n","Best parameters for SVC: {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}, Best F1 Score: 0.88\n","Vectorizer: TfidfVectorizer(), Classifier: SVC, Preprocess: Stop_words, Accuracy: 0.88, F1 Score: 0.86\n","Tuning parameters for MultinomialNB with Stop_words preprocessing...\n","Best parameters for MultinomialNB: {'classifier__alpha': 0.5}, Best F1 Score: 0.87\n","Vectorizer: TfidfVectorizer(), Classifier: MultinomialNB, Preprocess: Stop_words, Accuracy: 0.88, F1 Score: 0.86\n","Tuning parameters for LogisticRegression with Lemmatizer and Stemmer preprocessing...\n","Best parameters for LogisticRegression: {'classifier__C': 1, 'classifier__max_iter': 100}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: LogisticRegression, Preprocess: Lemmatizer and Stemmer, Accuracy: 0.95, F1 Score: 0.95\n","Tuning parameters for SVC with Lemmatizer and Stemmer preprocessing...\n","Best parameters for SVC: {'classifier__C': 1, 'classifier__gamma': 'scale', 'classifier__kernel': 'rbf'}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: SVC, Preprocess: Lemmatizer and Stemmer, Accuracy: 0.97, F1 Score: 0.97\n","Tuning parameters for MultinomialNB with Lemmatizer and Stemmer preprocessing...\n","Best parameters for MultinomialNB: {'classifier__alpha': 1.0}, Best F1 Score: 0.92\n","Vectorizer: TfidfVectorizer(), Classifier: MultinomialNB, Preprocess: Lemmatizer and Stemmer, Accuracy: 0.97, F1 Score: 0.97\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.stem import WordNetLemmatizer, PorterStemmer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","# Download necessary NLTK data files (run once)\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Import classifier packages\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","\n","def load_data(facts_file, fakes_file):\n","    with open(facts_file, 'r', encoding='utf-8') as f:\n","        facts = f.readlines()\n","    with open(fakes_file, 'r', encoding='utf-8') as f:\n","        fakes = f.readlines()\n","    # Create labels\n","    facts = [(fact.strip(), 1) for fact in facts]\n","    fakes = [(fake.strip(), 0) for fake in fakes]\n","    return facts + fakes\n","\n","\n","# Preprocess and split the dataset\n","def preprocess_and_split(data, method):\n","    # Create a DataFrame\n","    df = pd.DataFrame(data, columns=['text', 'label'])\n","\n","    # Apply preprocessing if method is not None\n","    if method is not None:\n","        df['text'] = df['text'].apply(lambda x: preprocess_text(x, method))\n","\n","    X = df['text']\n","    y = df['label']\n","\n","    # Split into train and test sets\n","    return train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","\n","# For 2 preprocesses\n","def double_preprocess_and_split(data, method1, method2):\n","    df = pd.DataFrame(data, columns=['text', 'label'])\n","    # Apply the first preprocessing method\n","    df['text'] = df['text'].apply(lambda x: preprocess_text(x, method1))\n","    # Apply the second preprocessing method\n","    df['text'] = df['text'].apply(lambda x: preprocess_text(x, method2))\n","    X = df['text']\n","    y = df['label']\n","    return train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","\n","def preprocess_text(text, method):\n","    stop_words = set(stopwords.words('english'))\n","    lemmatizer = WordNetLemmatizer()\n","    stemmer = PorterStemmer()\n","\n","    # Tokenize the text\n","    words = word_tokenize(text.lower())\n","\n","    # Apply preprocessing method\n","    if method == 'Lemmatizer':\n","        words = [lemmatizer.lemmatize(word) for word in words]\n","    elif method == 'Stemmer':\n","        words = [stemmer.stem(word) for word in words]\n","    elif method == 'Stop_words':\n","        words = [word for word in words if word.isalnum() and word not in stop_words]\n","\n","    return ' '.join(words)\n","\n","\n","# Build a pipeline with different classifiers\n","def build_pipeline(vectorizer, classifier):\n","    return Pipeline([\n","        ('vectorizer', vectorizer),\n","        ('classifier', classifier)\n","    ])\n","\n","\n","# Function to perform parameter tuning using GridSearchCV\n","def perform_grid_search(pipeline, param_grid, X_train, y_train):\n","    grid_search = GridSearchCV(pipeline, param_grid, scoring='f1', cv=5, n_jobs=-1)\n","    grid_search.fit(X_train, y_train)\n","    return grid_search.best_params_, grid_search.best_score_\n","\n","\n","# Main function to run experiments\n","def run_experiments():\n","    # Load and split data\n","    data = load_data('/content/drive/MyDrive/facts.txt', '/content/drive/MyDrive/fakes.txt')\n","\n","    # Define vectorizers and classifiers\n","    vectorizers = [\n","        TfidfVectorizer()\n","    ]\n","\n","    classifiers = [\n","        LogisticRegression(max_iter=1000),\n","        SVC(),\n","        MultinomialNB()\n","    ]\n","\n","    preprocessors = [None, 'Lemmatizer', 'Stemmer', 'Stop_words']\n","\n","    # Define parameter grids for each classifier\n","    param_grids = {\n","        'LogisticRegression': {\n","            'classifier__C': [0.1, 1, 10],\n","            'classifier__max_iter': [100, 300, 1000]\n","        },\n","        'SVC': {\n","            'classifier__C': [0.1, 1, 10],\n","            'classifier__kernel': ['linear', 'rbf'],\n","            'classifier__gamma': ['scale', 'auto']\n","        },\n","        'MultinomialNB': {\n","            'classifier__alpha': [0.5, 1.0, 1.5]\n","        }\n","    }\n","\n","    for preprocess in preprocessors:\n","        X_train, X_test, y_train, y_test = preprocess_and_split(data, preprocess)\n","\n","        for vectorizer in vectorizers:\n","            for classifier in classifiers:\n","                classifier_name = classifier.__class__.__name__\n","                pipeline = build_pipeline(vectorizer, classifier)\n","\n","                # Perform parameter tuning if a grid is defined for the classifier\n","                if classifier_name in param_grids:\n","                    print(f\"Tuning parameters for {classifier_name} with {preprocess} preprocessing...\")\n","                    best_params, best_score = perform_grid_search(pipeline, param_grids[classifier_name], X_train, y_train)\n","                    print(f\"Best parameters for {classifier_name}: {best_params}, Best F1 Score: {best_score:.2f}\")\n","\n","                    # Set the best parameters in the pipeline\n","                    pipeline.set_params(**best_params)\n","\n","                # Fit the model with the best parameters and evaluate\n","                pipeline.fit(X_train, y_train)\n","                y_pred = pipeline.predict(X_test)\n","                accuracy = accuracy_score(y_test, y_pred)\n","                f1 = f1_score(y_test, y_pred, pos_label=1)\n","                print(f'Vectorizer: {vectorizer}, Classifier: {classifier_name}, Preprocess: {preprocess}, '\n","                      f'Accuracy: {accuracy:.2f}, F1 Score: {f1:.2f}')\n","\n","    # Applying both lemmatizer and stemmer\n","    X_train, X_test, y_train, y_test = double_preprocess_and_split(data, \"Lemmatizer\", \"Stemmer\")\n","    for vectorizer in vectorizers:\n","        for classifier in classifiers:\n","            classifier_name = classifier.__class__.__name__\n","            pipeline = build_pipeline(vectorizer, classifier)\n","\n","            # Perform parameter tuning if a grid is defined for the classifier\n","            if classifier_name in param_grids:\n","                print(f\"Tuning parameters for {classifier_name} with Lemmatizer and Stemmer preprocessing...\")\n","                best_params, best_score = perform_grid_search(pipeline, param_grids[classifier_name], X_train, y_train)\n","                print(f\"Best parameters for {classifier_name}: {best_params}, Best F1 Score: {best_score:.2f}\")\n","\n","                # Set the best parameters in the pipeline\n","                pipeline.set_params(**best_params)\n","\n","            # Fit the model with the best parameters and evaluate\n","            pipeline.fit(X_train, y_train)\n","            y_pred = pipeline.predict(X_test)\n","            accuracy = accuracy_score(y_test, y_pred)\n","            f1 = f1_score(y_test, y_pred, pos_label=1)\n","            print(f'Vectorizer: {vectorizer}, Classifier: {classifier_name}, '\n","                  f'Preprocess: Lemmatizer and Stemmer, Accuracy: {accuracy:.2f}, F1 Score: {f1:.2f}')\n","\n","\n","if __name__ == '__main__':\n","    run_experiments()\n","\n","\n"]}]}